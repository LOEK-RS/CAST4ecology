[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "",
    "text": "# for spatial data handling\nlibrary(terra)\nlibrary(sf)\n\n\n# tidyverse functionality\nlibrary(tidyverse)\n\n# data acquisition\nlibrary(geodata)\nlibrary(rnaturalearth)\n\n# modelling\nlibrary(caret)\nlibrary(CAST)\n\n# visuals\nlibrary(tmap)\nlibrary(viridis)\nlibrary(scales)\n\n\n\n\n\n\nSet up directories\ndir.create(\"raw\") # for raw downloaded data\ndir.create(\"data\") # for preprocessed input data\ndir.create(\"modelling\") # for models and outcomes\n\n\n\n\n\nThis part is optional if you have the data already.\n\n\nGet modeldomain and predictors\n# define region: all of south america\nmodeldomain = rnaturalearth::ne_countries(continent = \"South America\", returnclass = \"sf\", scale = 110)\n\n# download or load worldclim for prediction\nwc = geodata::worldclim_global(var = \"bio\", res = 5, path = \"raw/\")\nelev = geodata::elevation_global(res = 5, path = \"raw/\")\n\n# reduce predictor data to model domain\npredictors = c(wc, elev)\npredictors = crop(predictors, modeldomain)\nnames(predictors) = names(predictors) |&gt; str_remove(pattern = \"wc2.1_5m_\") # clean up layer names\n\n\n\n\n\n\n\nDownload sPlotOpen\n# download sPlotOpen if not already done\nif(!file.exists(\"raw/splotopen/sPlotOpen.RData\")){\n  download.file(\"https://idata.idiv.de/ddm/Data/DownloadZip/3474?version=5779\", destfile = \"raw/splotopen.zip\")\n  unzip(\"raw/splotopen.zip\", exdir = \"raw/splotopen\")\n  unzip(\"raw/splotopen/sPlotOpen.RData(2).zip\", exdir = \"raw/splotopen\")\n}\n\n\n\n\nSpecies Richness for South America\n# Gather Response Variable: sPlotOpen Species Richness for South America\n## see Appendix 1 of https://doi.org/10.1111/geb.13346\nload(\"raw/splotopen/sPlotOpen.RData\")\n\nsplot = header.oa |&gt;\n    filter(Resample_1 == TRUE) |&gt;\n    filter(Continent == \"South America\") |&gt; \n    st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |&gt; \n    left_join(CWM_CWV.oa |&gt; select(c(\"PlotObservationID\", \"Species_richness\"))) |&gt; \n    select(c(\"PlotObservationID\", \"GIVD_ID\", \"Country\", \"Biome\",\n             \"Species_richness\")) |&gt; \n    na.omit()\n\n# cleanup workspace\nrm(CWM_CWV.oa, DT2.oa, header.oa, metadata.oa, reference.oa, sPlotOpen_citation)\n\n\n\n\nCompile response and predictors as reference samples\n# skipping: extracting worldclim in full resolution in order to get more training data\n# this would take long and requires a lot of ram/cpu since global worldclim is a large file\n\nif(FALSE){\n  \nwcf = rast(list.files(\"~/data/global_environmental_layer/geodata_30s/\", full.names = TRUE))\nwcf = crop(wcf, modeldomain)\nnames(wcf) = names(wcf) |&gt; str_remove(pattern = \"wc2.1_30s_\")\nwcf$lat = terra::init(wcf, \"y\")\nwcf$lon = terra::init(wcf, \"x\")\nwcf = c(wcf, wcf_terrain)\n\n# extract predictor values and attach to response\nsplot = terra::extract(wcf, splot, ID = FALSE, bind = TRUE) |&gt;\n    st_as_sf() |&gt; \n    na.omit()\n\n# only keep unique locations\n## some reference sample locations are in the same predictor stack pixel\n## this can lead to erroneous models and misleading validations\nplots_uni = splot[!duplicated(c(splot$lat, splot$lon)),]\nplots_uni = plots_uni |&gt; na.omit()\nplots_uni$lat = NULL\nplots_uni$lon = NULL\n\n\n}\n\n# instead, we compiled the predictor data for reference samples:\nsplot_predictors = readRDS(\"reference_predictors.RDS\")\nplots = right_join(splot, splot_predictors, by = join_by(\"PlotObservationID\"))"
  },
  {
    "objectID": "index.html#preparations",
    "href": "index.html#preparations",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "",
    "text": "# for spatial data handling\nlibrary(terra)\nlibrary(sf)\n\n\n# tidyverse functionality\nlibrary(tidyverse)\n\n# data acquisition\nlibrary(geodata)\nlibrary(rnaturalearth)\n\n# modelling\nlibrary(caret)\nlibrary(CAST)\n\n# visuals\nlibrary(tmap)\nlibrary(viridis)\nlibrary(scales)\n\n\n\n\n\n\nSet up directories\ndir.create(\"raw\") # for raw downloaded data\ndir.create(\"data\") # for preprocessed input data\ndir.create(\"modelling\") # for models and outcomes\n\n\n\n\n\nThis part is optional if you have the data already.\n\n\nGet modeldomain and predictors\n# define region: all of south america\nmodeldomain = rnaturalearth::ne_countries(continent = \"South America\", returnclass = \"sf\", scale = 110)\n\n# download or load worldclim for prediction\nwc = geodata::worldclim_global(var = \"bio\", res = 5, path = \"raw/\")\nelev = geodata::elevation_global(res = 5, path = \"raw/\")\n\n# reduce predictor data to model domain\npredictors = c(wc, elev)\npredictors = crop(predictors, modeldomain)\nnames(predictors) = names(predictors) |&gt; str_remove(pattern = \"wc2.1_5m_\") # clean up layer names\n\n\n\n\n\n\n\nDownload sPlotOpen\n# download sPlotOpen if not already done\nif(!file.exists(\"raw/splotopen/sPlotOpen.RData\")){\n  download.file(\"https://idata.idiv.de/ddm/Data/DownloadZip/3474?version=5779\", destfile = \"raw/splotopen.zip\")\n  unzip(\"raw/splotopen.zip\", exdir = \"raw/splotopen\")\n  unzip(\"raw/splotopen/sPlotOpen.RData(2).zip\", exdir = \"raw/splotopen\")\n}\n\n\n\n\nSpecies Richness for South America\n# Gather Response Variable: sPlotOpen Species Richness for South America\n## see Appendix 1 of https://doi.org/10.1111/geb.13346\nload(\"raw/splotopen/sPlotOpen.RData\")\n\nsplot = header.oa |&gt;\n    filter(Resample_1 == TRUE) |&gt;\n    filter(Continent == \"South America\") |&gt; \n    st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |&gt; \n    left_join(CWM_CWV.oa |&gt; select(c(\"PlotObservationID\", \"Species_richness\"))) |&gt; \n    select(c(\"PlotObservationID\", \"GIVD_ID\", \"Country\", \"Biome\",\n             \"Species_richness\")) |&gt; \n    na.omit()\n\n# cleanup workspace\nrm(CWM_CWV.oa, DT2.oa, header.oa, metadata.oa, reference.oa, sPlotOpen_citation)\n\n\n\n\nCompile response and predictors as reference samples\n# skipping: extracting worldclim in full resolution in order to get more training data\n# this would take long and requires a lot of ram/cpu since global worldclim is a large file\n\nif(FALSE){\n  \nwcf = rast(list.files(\"~/data/global_environmental_layer/geodata_30s/\", full.names = TRUE))\nwcf = crop(wcf, modeldomain)\nnames(wcf) = names(wcf) |&gt; str_remove(pattern = \"wc2.1_30s_\")\nwcf$lat = terra::init(wcf, \"y\")\nwcf$lon = terra::init(wcf, \"x\")\nwcf = c(wcf, wcf_terrain)\n\n# extract predictor values and attach to response\nsplot = terra::extract(wcf, splot, ID = FALSE, bind = TRUE) |&gt;\n    st_as_sf() |&gt; \n    na.omit()\n\n# only keep unique locations\n## some reference sample locations are in the same predictor stack pixel\n## this can lead to erroneous models and misleading validations\nplots_uni = splot[!duplicated(c(splot$lat, splot$lon)),]\nplots_uni = plots_uni |&gt; na.omit()\nplots_uni$lat = NULL\nplots_uni$lon = NULL\n\n\n}\n\n# instead, we compiled the predictor data for reference samples:\nsplot_predictors = readRDS(\"reference_predictors.RDS\")\nplots = right_join(splot, splot_predictors, by = join_by(\"PlotObservationID\"))"
  },
  {
    "objectID": "index.html#part-1-a-simple-model",
    "href": "index.html#part-1-a-simple-model",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "Part 1: A simple model",
    "text": "Part 1: A simple model\n\nWording\n\n## Wording from now on:\n# 1. plots: reference samples\n# 2. predictors: spatially continuous predictor stack\n# 3. modeldomain: where we want to predict (all of south america)\n# 4. predictor_names: names of predictors in the reference samples and the predictor stack\n# 5. response_name: name of the response variable in plots (what we want to model)\n\npredictor_names = names(predictors)\nresponse_name = \"Species_richness\"\ntraining_data = plots |&gt; st_drop_geometry() # reference samples without coordinates\n\n\n\nRandom Forest with Random Cross Validation\n\nset.seed(6502)\nrfmodel_rcv = caret::train(x = training_data |&gt; select(all_of(predictor_names)),\n                           y = training_data |&gt; pull(response_name),\n                           method = \"ranger\",\n                           num.trees = 100,\n                           trControl = trainControl(method = \"cv\",\n                                                    savePredictions = \"final\"))\n\nrfmodel_rcv\n\nRandom Forest \n\n645 samples\n 20 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 581, 581, 581, 581, 580, 580, ... \nResampling results across tuning parameters:\n\n  mtry  splitrule   RMSE      Rsquared   MAE     \n   2    variance    27.35229  0.6223699  16.12647\n   2    extratrees  27.86673  0.6094472  16.58850\n  11    variance    28.06613  0.6024260  16.40946\n  11    extratrees  27.99829  0.6051649  16.42961\n  20    variance    27.53063  0.6169278  15.96663\n  20    extratrees  27.73639  0.6136432  16.19936\n\nTuning parameter 'min.node.size' was held constant at a value of 5\nRMSE was used to select the optimal model using the smallest value.\nThe final values used for the model were mtry = 2, splitrule = variance\n and min.node.size = 5.\n\nglobal_validation(rfmodel_rcv)\n\n      RMSE   Rsquared        MAE \n27.8067725  0.6064448 16.1204080 \n\n\n\n\nFirst prediction of Species Richness\n\nrcv_prediction = predict(predictors, rfmodel_rcv, na.rm = TRUE)\n\n\n\nMap creation with tmap\ntm_shape(rcv_prediction)+\n    tm_raster(title = \"Predicted \\nSpecies Richness\", style = \"cont\",\n              palette = mako(50, begin = 0.2),\n              legend.reverse = TRUE)+\n        tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.just = \"left\",\n              frame = FALSE)\n\n\n\n\n\n\n\nThe problem\n\ndistance between reference samples and prediction domain is large\nrandom CV does not represent actual prediction task\nstandard validation approach is not sufficient\n\n\nrcv_geodist = plot_geodist(plots, modeldomain, unit = \"km\", showPlot = FALSE)\nrcv_geodist$plot + scale_x_log10() + theme_light()"
  },
  {
    "objectID": "index.html#part-2-map-accuracy-via-spatial-cross-validation-cv",
    "href": "index.html#part-2-map-accuracy-via-spatial-cross-validation-cv",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "Part 2: Map accuracy via spatial cross-validation (cv)",
    "text": "Part 2: Map accuracy via spatial cross-validation (cv)\n\nSetting up knndm-cv\n\nsetting up cv folds such that between-folds distance matches sample-prediction distance\ncv more representative of actual prediction task\n\n\nknn_setup = CAST::knndm(tpoints = st_transform(plots, 4326),\n                        modeldomain = st_transform(modeldomain, 4326), \n                        samplesize = 4000, k = 10)\nplots$fold = knn_setup$clusters\n\nplot(knn_setup)\n\n\n\n\n\n\nknndm-cv visualization with tmap and ggplot2\ntm_shape(modeldomain)+\n    tm_borders()+\n    tm_shape(plots)+\n    tm_symbols(col = \"fold\", style = \"cat\",\n               legend.col.reverse = FALSE,\n               size = 0.2, title.col = \"knndm Folds\",\n               legend.col.is.portrait = FALSE)+\n    tm_layout(frame = FALSE)\ngd = plot_geodist(plots,\n                  modeldomain,\n                  cvfolds = plots$fold,\n                  showPlot = FALSE)\ngd$plot + \n    scale_y_continuous(expand = c(0,0))+\n    scale_x_continuous(expand = c(0,0),\n                       trans = \"log10\",\n                       labels = trans_format(\"log10\", math_format(10^.x)))+\n    theme_light()+\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forest Model with knndm-cv\n\nset.seed(51)\nrfmodel_knndmcv = caret::train(x = training_data |&gt; select(all_of(predictor_names)),\n                           y = training_data |&gt; pull(response_name),\n                           method = \"ranger\",\n                           num.trees = 100,\n                           trControl = trainControl(method = \"cv\",\n                                                    index = knn_setup$indx_train,\n                                                    indexOut = knn_setup$indx_test,\n                                                    savePredictions = \"final\"),\n                           importance = \"permutation\")\n\nglobal_validation(rfmodel_knndmcv)\n\n      RMSE   Rsquared        MAE \n36.9920558  0.3779557 22.5012158 \n\n\n\nprediction results should be very similar to before since we only changes the validation strategy, not the model itself\n\n\nknndmcv_prediction = predict(predictors, rfmodel_knndmcv, na.rm = TRUE)"
  },
  {
    "objectID": "index.html#part-3-evaluating-the-area-of-applicability",
    "href": "index.html#part-3-evaluating-the-area-of-applicability",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "Part 3: Evaluating the Area of Applicability",
    "text": "Part 3: Evaluating the Area of Applicability\n\nDissimilarity between reference samples\n\nknndmcv_trainDI = trainDI(rfmodel_knndmcv)\nknndmcv_trainDI\n\nDI of 645 observation \nPredictors: bio_1 bio_2 bio_3 bio_4 bio_5 bio_6 bio_7 bio_8 bio_9 bio_10 bio_11 bio_12 bio_13 bio_14 bio_15 bio_16 bio_17 bio_18 bio_19 elev \n\nAOA Threshold: 0.3841501\n\nplot(knndmcv_trainDI)\n\n\n\n\n\n\nFrom dissimilarity to area of applicability\n\naoa_knndmcv = CAST::aoa(predictors, model = rfmodel_knndmcv, trainDI = knndmcv_trainDI)\nplot(aoa_knndmcv)\n\n\n\n\n\n\nMap creation with tmap\ntm_shape(aoa_knndmcv$DI)+\n    tm_raster(palette = viridis(50), style = \"cont\", legend.reverse = TRUE, breaks = c(0,0.1,0.368,0.5,1))+\n            tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.just = \"left\",\n              frame = FALSE)\n\n\n\n\n\nMap creation with tmap\ntm_shape(knndmcv_prediction)+\n    tm_raster(title = \"Predicted \\nSpecies Richness\", style = \"cont\",\n              palette = mako(50, begin = 0.2),\n              legend.reverse = TRUE)+\n    tm_shape(aoa_knndmcv$AOA)+\n    tm_raster(palette = c(\"1\" = NA, \"0\" = \"darkgoldenrod1\"), style = \"cat\", legend.show = FALSE)+\n    tm_add_legend(type = \"fill\", col = \"darkgoldenrod1\", border.lwd = 0,labels = \"Outside AOA\")+\n        tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.just = \"left\",\n              frame = FALSE)"
  },
  {
    "objectID": "index.html#part-4-spatial-variable-selection",
    "href": "index.html#part-4-spatial-variable-selection",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "Part 4: Spatial Variable Selection",
    "text": "Part 4: Spatial Variable Selection\n\nsimplify the model by selecting predictors based on their performance in new regions\nnew regions are defined by spatial cv folds (here knndm approach)\n\n\nset.seed(2516)\nffs_knndmcv = CAST::ffs(predictors = training_data |&gt; select(all_of(predictor_names)),\n                      response = training_data |&gt; pull(response_name),\n                      method = \"ranger\",\n                      num.trees = 100,\n                      minVar = 2,\n                      tuneGrid = expand.grid(splitrule = \"variance\",\n                                             mtry = 2,\n                                             min.node.size = 5),\n                      trControl = trainControl(method = \"cv\",\n                                               number = 10,\n                                               index = knn_setup$indx_train,\n                                               indexOut = knn_setup$indx_test,\n                                               savePredictions = \"final\"),\n                      importance = \"permutation\",\n                      verbose = FALSE)\n\n\n\nCompare Model Results\ncv_results = rbind(global_validation(rfmodel_rcv),\n    global_validation(rfmodel_knndmcv),\n    global_validation(ffs_knndmcv)) |&gt; \n    as.data.frame() |&gt; mutate(\"CV\" = c(\"random\", \"knndm\", \"knndm\"),\n                              \"predictors\" = c(ncol(rfmodel_rcv$trainingData)-1,\n                                               ncol(rfmodel_knndmcv$trainingData)-1, \n                                               ncol(ffs_knndmcv$trainingData)-1))\nknitr::kable(cv_results)\n\n\n\n\n\nRMSE\nRsquared\nMAE\nCV\npredictors\n\n\n\n\n27.80677\n0.6064448\n16.12041\nrandom\n20\n\n\n36.99206\n0.3779557\n22.50122\nknndm\n20\n\n\n34.70287\n0.4227883\n22.18723\nknndm\n6"
  },
  {
    "objectID": "index.html#part-5-spatially-explicit-error-mapping",
    "href": "index.html#part-5-spatially-explicit-error-mapping",
    "title": "CAST4Ecology Modelling Tutorial",
    "section": "Part 5: Spatially Explicit Error Mapping",
    "text": "Part 5: Spatially Explicit Error Mapping\n\ntranslating the DI to RMSE\nmaximizing AOA by feature space cluster cv\n\n\nffs_prediction = predict(predictors, ffs_knndmcv, na.rm = TRUE)\naoa_ffs = aoa(predictors, model = ffs_knndmcv)\n\nset.seed(10)\nffs_calib = calibrate_aoa(aoa_ffs, model = ffs_knndmcv, multiCV = TRUE, length.out = 6)\n\n\n\n\n\n\nMap creation with tmap\ntm_shape(ffs_prediction)+\n    tm_raster(title = \"Predicted \\nSpecies Richness\", style = \"cont\",\n              palette = mako(50, begin = 0.2),\n              legend.reverse = TRUE)+\n    tm_shape(ffs_calib$AOA$AOA)+\n    tm_raster(palette = c(\"1\" = NA, \"0\" = \"darkgoldenrod1\"), style = \"cat\", legend.show = FALSE)+\n    tm_add_legend(type = \"fill\", col = \"darkgoldenrod1\", border.lwd = 0,labels = \"Outside AOA\")+\n        tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.just = \"left\",\n              frame = FALSE)\n\n\n\n\n\nMap creation with tmap\ntm_shape(ffs_calib$AOA$expected_RMSE)+\n    tm_raster(title = \"Expected \\nRMSE\",style = \"cont\", legend.reverse = TRUE, palette = mako(50, direction = -1))+\n    tm_shape(ffs_calib$AOA$AOA)+\n    tm_raster(palette = c(\"1\" = NA, \"0\" = \"darkgoldenrod1\"), style = \"cat\", legend.show = FALSE)+\n    tm_add_legend(type = \"fill\", col = \"darkgoldenrod1\", border.lwd = 0,labels = \"Outside AOA\")+\n            tm_layout(legend.position = c(\"right\", \"bottom\"),\n              legend.just = \"left\",\n              frame = FALSE)"
  }
]